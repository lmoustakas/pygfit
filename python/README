## INSTALLATION ##
Start by unzipping the pygfit tar file (which you have obviously done already) and place the pygfit folder in either your working directory or your python path (http://docs.python.org/using/cmdline.html#envvar-PYTHONPATH).  For those new to python, this means that the pygfit *folder* should be in your python path.  So for example if you might have your .cshrc file say:

setenv PYTHONPATH '/home/py/mods/'

And then the pygfit.py file (and similarly all other files and folders from this tar file) should be found at '/home/py/mods/pygfit/pygfit.py'

Pygfit is intended to be run from the command line.  The basic calling sequence is:

/path/to/pygfit/pygfit.py config_file log_file warn_file

You can leave out any of the file names and instead they will default to:

/path/to/pygfit/pygfit.py pygfit.config pygfit.log pygfit.warn

You can dump a configuration file with all the default settings

/path/to/pygfit/pygfit.py --config > pygfit.config

I've made up a functional pygfit example.  It can be downloaded from:

www.baryons.org/tars/pygfit_ch1_example_clean.tar.gz

The finished results are also packed up and can be downloaded for comparison from here:

www.baryons.org/tars/pygfit_ch1_example_clean.tar.gz

to run it make sure pygfit is installed, unzip the example files, and then just type:

/path/to/pygfit/pygfit.py

It will generate an output catalog called 'pygfit.cat'.  Right now it is set to output a binary fits table.  If you prefer ascii files just edit pygfit.config and set OUTPUT_FORMAT to 'ascii'

Here is a description of the source extractor configuration settings:

## source extractor settings ##
pygfit uses source extractor to detect objects in the low resolution images.  It will only fit objects in the low resolution image if they are found by the source extractor run, so make sure and tweak the source extractor run appropriately.  It is best to minimize the amount of deblending done by source extractor, since that is obviously the whole point of pygfit.  So the first set of parameters controls this source extractor run, which pygfit executes itself.  You just have to tell it the filename of a valid source extractor configuration file (EXTRACTOR_CONFIG), an output name for the source extractor catalog (EXTRACTOR_CATALOG), the location of the source extractor executable (EXTRACTOR_CMD), and the name of the source extractor parameters file (EXTRACTOR_PARAMS).  You don't have to make the source extractor parameters file yourself, as it is generated automatically by pygfit - pygfit just needs to know where to keep it.

## high resolution catalog settings ##
For both input and output it will work with either ascii files or fits binary tables depending on your preference.  It will automatically detect which type your input catalog is.  The details for the high resolution catalog are set by the HRES_CATALOG, HRES_ROTANGLE, and HRES_PIXSCALE fields.  These should be pretty self-explanatory.  In the default configuration file there is a large block after the high resolution catalog settings called "Column layout of the high resolution catalog".  This set of parameters tells pygfit where to find everything it needs in the high resolution catalog.  If your input catalog is an ascii file, then these parameters should be the zero-indexed column number that corresponds to the given data field.  For example, if your first column is the model type (which should be a string of either 'point' or 'sersic') then MODEL_TYPE should be set to 0.  If your input catalog is a binary fits table, then instead of column numbers these parameters should be set to the appropriate column names in the high resolution catalog.  For both types of input catalogs the MAG and POINT_MAG columns are allowed to point to the same column in the catalog, if desired.

## low resolution image settings ##
Next up are the configuration settings for the low resolution image.  You need the image, an rms image, and a psf image.  The psf file should be an odd-sized square with the PSF star centered in the image.  If it isn't a square, or isn't odd, then pygfit will stick a zero-value pixel border around it to make it so.

## Fitting settings ##
pygfit is multithreaded and N_THREADS sets the number of threads to use.  Unfortunately there is a lot of data to communicate to new processes, and it isn't very efficient.  In my tests using 8 threads only sped it up by a factor of 3.  Also be aware of the possibility of running out of memory with too many threads going.  Before fitting pygfit will attempt to measure an astrometric offset between the high resolution catalog and low resolution image.  GLOBAL_MAX_SHIFT gives the maximum astrometric offset searched for and corrected for (in arcseconds).  N_ALIGN gives the maximum number of alignment objects used, and ALIGN_MIN_MAG and ALIGN_MAX_MAG set the magnitude range and object must fall in to be used in the alignment step.  Objects have to be isolated to be included in the alignment, so you might have to use a borader magnitude range than expected to find enough isolated objects.

During the fitting the positions of the objects are allowed to jitter individually by a small amount set by MAX_SHIFT (in arcseconds).  Fitting is limited to a magnitude range set by MIN_MAG and MAX_MAG.  This lets you exclude very bright objects which can take a very long time to fit and also exclude things that are fainter than you might care about.  Finally, PAD_LENGTH sets the size of the padding region to use.  Before modeling the images are buffered by a border of this size to leave room for interpolation and convolution.

## output settings ##
These should be relatively self-explanatory.  Three of note are OUTPUT_CATALOG which is the filename of the output catalog and OUTPUT_FORMAT which can be either 'fits' or 'ascii' and tells pygfit whether or not to output a fits binary table or ascii file.  There are many output columns and if you don't want them all in your output file you can tell them which to output (and what order to put them in).  If you comment out the output columns line then pygfit will output all columns.  Here are the allowed output columns and a brief description of what they are:

lres_id          The object id from the low resolution catalog (source extractor 'number')
hres_id          The object id from the high resolution catalog
nblend           The number of objects in the blend
nearest          The distance to the nearest object in the blend
nearest_mag      The fitted magnitude of the nearest object in the blend
model            The model type 'sersic' or 'point'
ra               Right Ascension
dec              Declination
x                X coordinate from low resolution image
y                Y coordinate from low resolution image
img_x            X coordinate on low resolution image stamp
img_y            Y coordinate on low resolution image stamp
mag              Fitted magnitude (-2.5*log10( flux ) + zpt)
mag_image        Magnitude in final model image (not very useful)
mag_initial      Magnitude in original model image (a diagnostic explained below)
mag_hres         Magnitude from the high resolution catalog
mag_brightest    Magnitude of the brightest object in the blend
mag_warning      Set to True when pygfit has detected a potential integration error (described below)
flux             The flux (in image data units) of the source
total_flux       The total fitted flux of all objects in the blend
total_mag        The total fitted magnitude of all objects in the blend (-2.5*log10( total_flux ) + zpt)
blend_fraction   The fraction of flux from the blend accounted for by this object (flux/total_flux)
sky              The fitted sky value (if sky fitting is enabled)
re_hres          Re in high resolution image pixels
re_lres          Re in low resolution image pixels
re_arcsecs       Re in arcseconds
n                Sersic index
pa               Position angle
ba               Axis ratio
chisq_nu         Reduced chisq of fit
chisq            Chisq of fit
nf               Degrees of freedom from fit

## integration errors ##
To dramatically improve execution time pygfit numerically integrates the sersic function when generating the model.  Numeric integration can be difficult in the center of the profile where the sersic function is very steep or changes quickly.  Pygfit uses a finer grid for numeric integration in the center of the profile to account for this.  However, the current method can still fail for very steep profiles (i.e. high sersic indexes).  This problem is strictly limited to profiles with n>7.5, and *maybe* down to n=7.  When the numeric integration fails the normalization for the sersic function is dramatically overestimated and you end up with a model that is substantially brighter than it should be.  When this happens, mag_initial ends up much brighter than mag_hres.  Therefore, this is a detectable error.  Pygfit has two ways of dealing with this, which is controlled by the 'USE_INTEGRATION' parameter in the pygfit.config file.  If USE_INTEGRATION is true then pygfit will perform the actual sersic integration for the central pixel: this always fixes the problem, but can be slow (especially for objects with high sersic indexes, i.e. these problematic galaxies).  If USE_INTEGRATION is false then pygfit does not do anything except set the mag_warning flag in the output catalog to true (assuming this column is being outputted).  The best fit magnitude will be very wrong for these flagged objects.  However this will not affect the quality of the fit: any objects blended with these objects will still be fine.  Why might you want to use this option?  Because the extra integration can slow things down dramatically, and 95% of the time objects with such high sersic indexes are not actually galaxies (or they are very poor sersic fits) and therefore you aren't interested in them anyway.


## simulations ##
Pygfit has a built in simulator for estimating errors.  The default settings seem to work pretty well.  It generates a large number of artificial galaxies, puts a few of them each into a large number of simulation frames, runs pygfit on the simulated frames, and then puts together a catalog with input mag vs output mag for all the simulated galaxies.  To run the simulations go to your pygfit directory and type:

/path/to/pygfit.py --simulate

It will generate a sims directory and put each simulated frame in its own subdirectory.  If something goes wrong you can just run the simulation command again and it will pick up where it left off.  When it is done it will put a few plots in the sims directory, as well as a binary fits table, results.cat.  This contains the input and output mags for all the simulated objects.  You can then use this catalog to estimate errors for your real galaxies in whatever way works best for your science.